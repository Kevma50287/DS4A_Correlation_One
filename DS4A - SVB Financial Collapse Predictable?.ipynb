{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08350a1e",
   "metadata": {},
   "source": [
    "# SEC - Filtering for Ratios and Expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0047c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "JSON_folder_path = './Json'\n",
    "files = os.listdir(JSON_folder_path)\n",
    "file = files[0]\n",
    "\n",
    "\n",
    "with open(JSON_folder_path + \"/\" + file) as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    us_gaap = data['facts']['us-gaap']\n",
    "    keys=[]\n",
    "    formatted_data = {}\n",
    "    formatted_data['entity_name'] = data['entityName']\n",
    "    for key in us_gaap:\n",
    "        keys.append(key.lower())\n",
    "        formatted_data[key] = us_gaap[key]\n",
    "\n",
    "search_key = [\"cash\", \"receivable\", \"payable\", \"asset\", \"liabili\", \"loan\", \"equit\", \"income\", \"expense\", \"interest\", \"deposit\"]\n",
    "print(keys)\n",
    "\n",
    "results={}\n",
    "for key in search_key:\n",
    "    matches = []\n",
    "    for account_name in keys:\n",
    "        if key in account_name:\n",
    "            matches.append(account_name)\n",
    "    results[key]=matches\n",
    "\n",
    "print(results['cash'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffa13347",
   "metadata": {},
   "source": [
    "# Yahoo Finance Webscraping w/ BeautifulSoup and Selenium\n",
    "\n",
    "How to use:\n",
    "1. Update login() with username and password params\n",
    "2. Update stock_tickers_arr to include tickers of companies to be scraped\n",
    "3. Hit run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fd5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "# Array of stock tickers to scrape\n",
    "stock_tickers_arr = [\n",
    "    \"SIVBQ\",\"JPM\",\"FRCB\",\n",
    "    \"WFC\",\"BAC\",\"DFS\",\n",
    "    \"MS\",\"PNC\",\"CS\",\n",
    "    \"DB\",\"COF\",\"C\",\n",
    "    \"KEY\",\"BK\",\"GS\",\n",
    "    \"HSBC\",\"MTB\",\"TD\",\n",
    "    \"FHN\",\"OVLY\",\"PACW\",\n",
    "    \"WAL\",\"SBNY\",\"ZION\",\n",
    "    \"CMA\",\"FCNCA\",\"EWBC\",\n",
    "    \"CFG\",\"MCBC\",\"NYCB\",\n",
    "]\n",
    "\n",
    "# Initialize default variables - don't change these\n",
    "path_to = {\n",
    "    'income_statement': \"/financials?p=\",\n",
    "    'balance_sheet':\"/balance-sheet?p=\",\n",
    "    'cashflow_statement':\"/cash-flow?p=\",\n",
    "    'key-statistics':\"/key-statistics?p=\"\n",
    "}\n",
    "stock_ticker = \"JPM\"\n",
    "stock_URL = (\n",
    "    \"https://finance.yahoo.com/quote/\" + stock_ticker + \"/financials?p=\" + stock_ticker\n",
    ")\n",
    "\n",
    "# Functions\n",
    "\n",
    "# Login to account. Yahoo Finance only gives the last 4 reporting periods, need Yahoo Finance Plus for complete hitorical FS data\n",
    "def login(username:str, password:str):\n",
    "    driver.get(stock_URL)\n",
    "\n",
    "    # Login to my account\n",
    "    sign_in_button=driver.find_element(By.ID, 'header-signin-link')\n",
    "    sign_in_button.click()\n",
    "    wait = WebDriverWait(driver, 10)  \n",
    "    element = wait.until(EC.presence_of_element_located((By.ID, 'login-username')))\n",
    "    login_username=driver.find_element(By.ID, 'login-username')\n",
    "\n",
    "    # Enter username\n",
    "    login_username.send_keys(username)\n",
    "    wait = WebDriverWait(driver, 10)  \n",
    "    element = wait.until(EC.presence_of_element_located((By.ID, 'login-signin')))\n",
    "    login_sign_in_button=driver.find_element(By.ID, 'login-signin')\n",
    "    login_sign_in_button.click()\n",
    "\n",
    "    # Maximum wait time of 10 seconds, wait for element to load\n",
    "    wait = WebDriverWait(driver, 10)  \n",
    "    element = wait.until(EC.presence_of_element_located((By.ID, 'login-passwd')))\n",
    "    login_passwd = driver.find_element(By.ID, 'login-passwd')\n",
    "\n",
    "    # Enter password\n",
    "    login_passwd.send_keys(password)\n",
    "    login_sign_in_button=driver.find_element(By.ID, 'login-signin')\n",
    "    login_sign_in_button.click()\n",
    "\n",
    "def get_URL_to(ticker: str, financial_statement_name: str):\n",
    "    stock_ticker = ticker\n",
    "    path = path_to[financial_statement_name]\n",
    "    URL = (\n",
    "        \"https://finance.yahoo.com/quote/\" + stock_ticker + path + stock_ticker\n",
    "    )\n",
    "    return URL\n",
    "\n",
    "#Only go to URL if it is different than the current URL\n",
    "def go_to_URL(URL):\n",
    "    current_url = driver.current_url\n",
    "    driver.get(URL)\n",
    "\n",
    "def expand_all_get_html():\n",
    "    time.sleep(2)\n",
    "    # Wait for expand button to load before clicking\n",
    "    wait = WebDriverWait(driver, 10)  \n",
    "    element = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'expandPf')))\n",
    "    expand_button = driver.find_element(By.CLASS_NAME, 'expandPf')\n",
    "    expand_button.click()\n",
    "\n",
    "    # Let page load new html before extracting\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Download HTML file\n",
    "    html_source = driver.page_source\n",
    "\n",
    "    return html_source\n",
    "\n",
    "def create_directory_if_not_exists(ticker):\n",
    "    directory = f'./CSV/{ticker}'\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def scrape_and_save_to_csv(html, ticker:str, financial_statement_name:str, period:str):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Find all table headers (Dates)\n",
    "    table_headers = soup.find(\"div\", {\"class\": \"D(tbhg)\"})\n",
    "    table_headers_row = table_headers.find_all(\"div\", {\"class\": \"D(ib)\"})\n",
    "    table_headers_names = []\n",
    "\n",
    "    for div in table_headers_row:\n",
    "        span = div.span\n",
    "        name = span.get_text()\n",
    "        table_headers_names.append(name)\n",
    "\n",
    "    table_column_length = len(table_headers_names)\n",
    "\n",
    "    # Find all table rows (Amounts)\n",
    "    table_rows = soup.find(\"div\", {\"class\": \"D(tbrg)\"})\n",
    "    table_rows_data = table_rows.find_all(\"div\", {\"class\": \"D(tbr)\"})\n",
    "    table_rows_data_arrays = []\n",
    "\n",
    "    for table_row in table_rows_data:\n",
    "        row_header_text = table_row.find(\"div\", {'class':\"Ta(start)\"}).find(\"span\").get_text()\n",
    "        row_data_array = table_row.find_all(\"div\", {'class':\"Ta(c)\"})\n",
    "        row_data_text_array = [row_header_text]\n",
    "\n",
    "        for div in row_data_array:\n",
    "            span = div.find(\"span\") if div.find(\"span\") != None else div\n",
    "            text = span.get_text()\n",
    "            row_data_text_array.append(text)\n",
    "        table_rows_data_arrays.append(row_data_text_array)\n",
    "\n",
    "\n",
    "    data_frame_object = {table_headers_names[0]:table_headers_names[1:]}\n",
    "\n",
    "    # First element in row array contains the row header\n",
    "    # Map it to an object and then convert into a dataframe\n",
    "    for data in table_rows_data_arrays:\n",
    "        data_frame_object[data[0]] = data[1:]\n",
    "\n",
    "    df = pd.DataFrame(data_frame_object)\n",
    "    # Save CSV\n",
    "    df.to_csv(f'./CSV/{ticker}/{financial_statement_name}_{period}.csv')\n",
    "\n",
    "def save_one_financial_statement(ticker:str, financial_statement_name:str, period:str):\n",
    "    create_directory_if_not_exists(ticker)\n",
    "    if period == 'quarterly':\n",
    "        URL = get_URL_to(ticker, financial_statement_name)\n",
    "        go_to_URL(URL)\n",
    "        wait = WebDriverWait(driver, 10)  \n",
    "        element = wait.until(EC.presence_of_element_located((By.XPATH, '//button[div[span[text()=\"Quarterly\"]]]')))\n",
    "        quarterly_button = driver.find_element(By.XPATH, '//button[div[span[text()=\"Quarterly\"]]]')\n",
    "        quarterly_button.click()\n",
    "        html_source = expand_all_get_html()\n",
    "        scrape_and_save_to_csv(html_source, ticker, financial_statement_name, period)\n",
    "    else:\n",
    "        URL = get_URL_to(ticker, financial_statement_name)\n",
    "        go_to_URL(URL)\n",
    "        html_source = expand_all_get_html()\n",
    "        scrape_and_save_to_csv(html_source, ticker, financial_statement_name, period)\n",
    "\n",
    "def save_all_financial_statements(ticker:str):\n",
    "    save_one_financial_statement(ticker, 'income_statement', 'annual')\n",
    "    save_one_financial_statement(ticker, 'income_statement', 'quarterly')\n",
    "    save_one_financial_statement(ticker, 'balance_sheet', 'annual')\n",
    "    save_one_financial_statement(ticker, 'balance_sheet', 'quarterly')\n",
    "    save_one_financial_statement(ticker, 'cashflow_statement', 'annual')\n",
    "    save_one_financial_statement(ticker, 'cashflow_statement', 'quarterly')\n",
    "\n",
    "def save_market_cap(ticker:str, period:str):\n",
    "    URL = get_URL_to(ticker, 'key-statistics')\n",
    "    go_to_URL(URL)\n",
    "    wait = WebDriverWait(driver, 10)  \n",
    "    element = wait.until(EC.presence_of_element_located((By.XPATH, f'//button[div[span[text()=\"{period}\"]]]')))\n",
    "    button = driver.find_element(By.XPATH, f'//button[div[span[text()=\"{period}\"]]]')\n",
    "    button.click()\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "\n",
    "    # Find all table headers (Dates)\n",
    "    table_headers = soup.find(\"thead\")\n",
    "    table_headers_row = table_headers.find_all(\"th\")\n",
    "    table_headers_names = []\n",
    "    for th in table_headers_row:\n",
    "        print(th)\n",
    "        span = th.find('span')\n",
    "        if span:\n",
    "            text = span.get_text()\n",
    "        else:\n",
    "            text = \"\"\n",
    "        table_headers_names.append(text)\n",
    "\n",
    "    table_column_length = len(table_headers_names)\n",
    "\n",
    "    # Find all table rows (Amounts)\n",
    "    table_rows = soup.find(\"tbody\")\n",
    "    table_rows_data = table_rows.find_all(\"tr\")\n",
    "    table_rows_data_arrays = []\n",
    "    for tr in table_rows_data:\n",
    "        row_data_array = []\n",
    "        for i, td in enumerate(tr):\n",
    "            if i == 0:\n",
    "                row_data_array.append(td.span.get_text())\n",
    "            else:\n",
    "                row_data_array.append(td.get_text())\n",
    "        table_rows_data_arrays.append(row_data_array)\n",
    "    \n",
    "    data_frame_object = {table_headers_names[0]:table_headers_names[1:]}\n",
    "\n",
    "    # First element in row array contains the row header\n",
    "    # Map it to an object and then convert into a dataframe\n",
    "    for data in table_rows_data_arrays:\n",
    "        data_frame_object[data[0]] = data[1:]\n",
    "\n",
    "    df = pd.DataFrame(data_frame_object)\n",
    "    # Save CSV\n",
    "    df.to_csv(f'./CSV/{ticker}/market_stats.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3eebd9",
   "metadata": {},
   "source": [
    "### Compilation of all appropriate CSV files\n",
    "\n",
    "**More info to be added soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "14a42081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilation of all appropriate csv files\n",
    "main_path = os.getcwd() + \"/CSV\"\n",
    "\n",
    "# Initializing dicts\n",
    "balance_sheet_df_collection = {}\n",
    "cashflow_statement_df_collection = {}\n",
    "income_statement_df_collection = {}\n",
    "market_stats_df_collection = {}\n",
    "\n",
    "collections = {\n",
    "    \"balance_sheet_quarterly.csv\": balance_sheet_df_collection,\n",
    "    \"cashflow_statement_quarterly.csv\": cashflow_statement_df_collection,\n",
    "    \"income_statement_quarterly.csv\": income_statement_df_collection,\n",
    "    \"market_stats.csv\": market_stats_df_collection\n",
    "}\n",
    "\n",
    "def process_csv_file(current_path, folder):\n",
    "    copy_df = pd.read_csv(current_path)\n",
    "    copy_df[\"Unnamed: 0\"] = (copy_df[\"Unnamed: 0\"] >= 0).astype(int).replace(1, folder)\n",
    "    column_names = copy_df.columns\n",
    "    return pd.DataFrame(copy_df, columns=column_names)\n",
    "\n",
    "for folder in os.listdir(main_path):\n",
    "    for csv_file in os.listdir(os.path.join(main_path, folder)):\n",
    "        current_path = os.path.join(main_path, folder, csv_file)\n",
    "        \n",
    "        if csv_file in collections:\n",
    "            collections[csv_file][folder] = process_csv_file(current_path, folder)\n",
    "\n",
    "\n",
    "balance_sheet_df = pd.concat(balance_sheet_df_collection)\n",
    "cashflow_statement_df = pd.concat(cashflow_statement_df_collection)\n",
    "income_statement_df = pd.concat(income_statement_df_collection)\n",
    "market_stats_df = pd.concat(market_stats_df_collection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1ac92",
   "metadata": {},
   "source": [
    "### Clean up of compiled dataframes\n",
    "\n",
    " - balance_sheet_df\n",
    " - cashflow_statement_df\n",
    " - income_statement_df\n",
    " - market_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b0ad3d",
   "metadata": {},
   "source": [
    "### Balance Sheet Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a97677c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Cash, Cash Equivalents &amp; Federal Funds Sold</th>\n",
       "      <th>Cash And Cash Equivalents</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Cash Equivalents</th>\n",
       "      <th>Cash And Due from Banks</th>\n",
       "      <th>Interest Bearing Deposits Assets</th>\n",
       "      <th>Restricted Cash And Investments</th>\n",
       "      <th>...</th>\n",
       "      <th>Properties</th>\n",
       "      <th>Line of Credit</th>\n",
       "      <th>Unrealized Gain Loss</th>\n",
       "      <th>Non Current Deferred Taxes Liabilities</th>\n",
       "      <th>Defined Pension Benefit</th>\n",
       "      <th>Due to Related Parties</th>\n",
       "      <th>Current Deferred Liabilities</th>\n",
       "      <th>Current Deferred Taxes Liabilities</th>\n",
       "      <th>Minimum Pension Liabilities</th>\n",
       "      <th>Other Capital Stock</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker Symbol</th>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">EWBC</th>\n",
       "      <th>0</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>67244898.0</td>\n",
       "      <td>6598731.0</td>\n",
       "      <td>5944443.0</td>\n",
       "      <td>760317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5184126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>64112150.0</td>\n",
       "      <td>4412997.0</td>\n",
       "      <td>3620805.0</td>\n",
       "      <td>534980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3085825.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>62576061.0</td>\n",
       "      <td>3686882.0</td>\n",
       "      <td>2793896.0</td>\n",
       "      <td>554260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2239636.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>62394283.0</td>\n",
       "      <td>4037556.0</td>\n",
       "      <td>2614762.0</td>\n",
       "      <td>688936.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1925826.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>62241456.0</td>\n",
       "      <td>6621647.0</td>\n",
       "      <td>4664825.0</td>\n",
       "      <td>571571.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4093254.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">SIVBQ</th>\n",
       "      <th>121</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>1992-09-30</td>\n",
       "      <td>1025700.0</td>\n",
       "      <td>223300.0</td>\n",
       "      <td>223300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221800.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>1992-06-30</td>\n",
       "      <td>915900.0</td>\n",
       "      <td>118700.0</td>\n",
       "      <td>118700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116500.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>1992-03-31</td>\n",
       "      <td>899800.0</td>\n",
       "      <td>127300.0</td>\n",
       "      <td>127300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124600.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>1991-12-31</td>\n",
       "      <td>869500.0</td>\n",
       "      <td>128200.0</td>\n",
       "      <td>128200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>1991-09-30</td>\n",
       "      <td>869200.0</td>\n",
       "      <td>154900.0</td>\n",
       "      <td>154900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151800.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3301 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Ticker       Date  Total Assets   \n",
       "Ticker Symbol Index                                   \n",
       "EWBC          0       EWBC 2023-03-31    67244898.0  \\\n",
       "              1       EWBC 2022-12-31    64112150.0   \n",
       "              2       EWBC 2022-09-30    62576061.0   \n",
       "              3       EWBC 2022-06-30    62394283.0   \n",
       "              4       EWBC 2022-03-31    62241456.0   \n",
       "...                    ...        ...           ...   \n",
       "SIVBQ         121    SIVBQ 1992-09-30     1025700.0   \n",
       "              122    SIVBQ 1992-06-30      915900.0   \n",
       "              123    SIVBQ 1992-03-31      899800.0   \n",
       "              124    SIVBQ 1991-12-31      869500.0   \n",
       "              125    SIVBQ 1991-09-30      869200.0   \n",
       "\n",
       "                     Cash, Cash Equivalents & Federal Funds Sold   \n",
       "Ticker Symbol Index                                                \n",
       "EWBC          0                                        6598731.0  \\\n",
       "              1                                        4412997.0   \n",
       "              2                                        3686882.0   \n",
       "              3                                        4037556.0   \n",
       "              4                                        6621647.0   \n",
       "...                                                          ...   \n",
       "SIVBQ         121                                       223300.0   \n",
       "              122                                       118700.0   \n",
       "              123                                       127300.0   \n",
       "              124                                       128200.0   \n",
       "              125                                       154900.0   \n",
       "\n",
       "                     Cash And Cash Equivalents      Cash  Cash Equivalents   \n",
       "Ticker Symbol Index                                                          \n",
       "EWBC          0                      5944443.0  760317.0               NaN  \\\n",
       "              1                      3620805.0  534980.0               NaN   \n",
       "              2                      2793896.0  554260.0               NaN   \n",
       "              3                      2614762.0  688936.0               NaN   \n",
       "              4                      4664825.0  571571.0               NaN   \n",
       "...                                        ...       ...               ...   \n",
       "SIVBQ         121                     223300.0       NaN          221800.0   \n",
       "              122                     118700.0       NaN          116500.0   \n",
       "              123                     127300.0       NaN          124600.0   \n",
       "              124                     128200.0       NaN          126000.0   \n",
       "              125                     154900.0       NaN          151800.0   \n",
       "\n",
       "                     Cash And Due from Banks   \n",
       "Ticker Symbol Index                            \n",
       "EWBC          0                    5184126.0  \\\n",
       "              1                    3085825.0   \n",
       "              2                    2239636.0   \n",
       "              3                    1925826.0   \n",
       "              4                    4093254.0   \n",
       "...                                      ...   \n",
       "SIVBQ         121                     1500.0   \n",
       "              122                     2200.0   \n",
       "              123                     2700.0   \n",
       "              124                     2200.0   \n",
       "              125                     3100.0   \n",
       "\n",
       "                     Interest Bearing Deposits Assets   \n",
       "Ticker Symbol Index                                     \n",
       "EWBC          0                                   NaN  \\\n",
       "              1                                   NaN   \n",
       "              2                                   NaN   \n",
       "              3                                   NaN   \n",
       "              4                                   NaN   \n",
       "...                                               ...   \n",
       "SIVBQ         121                                 NaN   \n",
       "              122                                 NaN   \n",
       "              123                                 NaN   \n",
       "              124                                 NaN   \n",
       "              125                                 NaN   \n",
       "\n",
       "                     Restricted Cash And Investments  ...  Properties   \n",
       "Ticker Symbol Index                                   ...               \n",
       "EWBC          0                                  NaN  ...         NaN  \\\n",
       "              1                                  NaN  ...         NaN   \n",
       "              2                                  NaN  ...         NaN   \n",
       "              3                                  NaN  ...         NaN   \n",
       "              4                                  NaN  ...         NaN   \n",
       "...                                              ...  ...         ...   \n",
       "SIVBQ         121                                NaN  ...         NaN   \n",
       "              122                                NaN  ...         NaN   \n",
       "              123                                NaN  ...         NaN   \n",
       "              124                                NaN  ...         NaN   \n",
       "              125                                NaN  ...         NaN   \n",
       "\n",
       "                     Line of Credit  Unrealized Gain Loss   \n",
       "Ticker Symbol Index                                         \n",
       "EWBC          0                 NaN                   NaN  \\\n",
       "              1                 NaN                   NaN   \n",
       "              2                 NaN                   NaN   \n",
       "              3                 NaN                   NaN   \n",
       "              4                 NaN                   NaN   \n",
       "...                             ...                   ...   \n",
       "SIVBQ         121               NaN                   NaN   \n",
       "              122               NaN                   NaN   \n",
       "              123               NaN                   NaN   \n",
       "              124               NaN                   NaN   \n",
       "              125               NaN                   NaN   \n",
       "\n",
       "                     Non Current Deferred Taxes Liabilities   \n",
       "Ticker Symbol Index                                           \n",
       "EWBC          0                                         NaN  \\\n",
       "              1                                         NaN   \n",
       "              2                                         NaN   \n",
       "              3                                         NaN   \n",
       "              4                                         NaN   \n",
       "...                                                     ...   \n",
       "SIVBQ         121                                       NaN   \n",
       "              122                                       NaN   \n",
       "              123                                       NaN   \n",
       "              124                                       NaN   \n",
       "              125                                       NaN   \n",
       "\n",
       "                     Defined Pension Benefit  Due to Related Parties   \n",
       "Ticker Symbol Index                                                    \n",
       "EWBC          0                          NaN                     NaN  \\\n",
       "              1                          NaN                     NaN   \n",
       "              2                          NaN                     NaN   \n",
       "              3                          NaN                     NaN   \n",
       "              4                          NaN                     NaN   \n",
       "...                                      ...                     ...   \n",
       "SIVBQ         121                        NaN                     NaN   \n",
       "              122                        NaN                     NaN   \n",
       "              123                        NaN                     NaN   \n",
       "              124                        NaN                     NaN   \n",
       "              125                        NaN                     NaN   \n",
       "\n",
       "                     Current Deferred Liabilities   \n",
       "Ticker Symbol Index                                 \n",
       "EWBC          0                               NaN  \\\n",
       "              1                               NaN   \n",
       "              2                               NaN   \n",
       "              3                               NaN   \n",
       "              4                               NaN   \n",
       "...                                           ...   \n",
       "SIVBQ         121                             NaN   \n",
       "              122                             NaN   \n",
       "              123                             NaN   \n",
       "              124                             NaN   \n",
       "              125                             NaN   \n",
       "\n",
       "                     Current Deferred Taxes Liabilities   \n",
       "Ticker Symbol Index                                       \n",
       "EWBC          0                                     NaN  \\\n",
       "              1                                     NaN   \n",
       "              2                                     NaN   \n",
       "              3                                     NaN   \n",
       "              4                                     NaN   \n",
       "...                                                 ...   \n",
       "SIVBQ         121                                   NaN   \n",
       "              122                                   NaN   \n",
       "              123                                   NaN   \n",
       "              124                                   NaN   \n",
       "              125                                   NaN   \n",
       "\n",
       "                     Minimum Pension Liabilities  Other Capital Stock  \n",
       "Ticker Symbol Index                                                    \n",
       "EWBC          0                              NaN                  NaN  \n",
       "              1                              NaN                  NaN  \n",
       "              2                              NaN                  NaN  \n",
       "              3                              NaN                  NaN  \n",
       "              4                              NaN                  NaN  \n",
       "...                                          ...                  ...  \n",
       "SIVBQ         121                            NaN                  NaN  \n",
       "              122                            NaN                  NaN  \n",
       "              123                            NaN                  NaN  \n",
       "              124                            NaN                  NaN  \n",
       "              125                            NaN                  NaN  \n",
       "\n",
       "[3301 rows x 133 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "balance_sheet_df.rename(columns = {\n",
    "    \"Unnamed: 0\":\"Ticker\",\n",
    "    \"Breakdown\":\"Date\",\n",
    "    \"SECURITIES_AND_INVESTMENTS\":\"Securities And Investments\",\n",
    "    \"Accounts receivables\":\"Accounts Receivables\"\n",
    "    }, inplace = True)\n",
    "balance_sheet_df[\"Date\"] = pd.to_datetime(balance_sheet_df[\"Date\"])\n",
    "balance_sheet_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "\n",
    "# Clean column types\n",
    "cols=[i for i in balance_sheet_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "for col in cols:\n",
    "    balance_sheet_df[col] = balance_sheet_df[col].astype(str).str.replace(',','')\n",
    "    balance_sheet_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values\n",
    "    balance_sheet_df[col]= balance_sheet_df[col].astype(float)\n",
    "balance_sheet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f426a",
   "metadata": {},
   "source": [
    "### Cashflow Statement Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e7d8e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "cashflow_statement_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "cashflow_statement_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "cashflow_statement_df.drop(0, level=1, axis=0, inplace=True) # Erase all ttm values as not necessary (trailing twelve months data not necessary)\n",
    "cashflow_statement_df[\"Date\"] = pd.to_datetime(cashflow_statement_df[\"Date\"]) # Updating column type to datetime\n",
    "\n",
    "# Clean column types\n",
    "cols=[i for i in cashflow_statement_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "for col in cols:\n",
    "    cashflow_statement_df[col] = cashflow_statement_df[col].astype(str).str.replace(',','')\n",
    "    cashflow_statement_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values but it works?\n",
    "    cashflow_statement_df[col]= cashflow_statement_df[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529dabd3",
   "metadata": {},
   "source": [
    "### Income Statement Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d7377168",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_statement_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "income_statement_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "income_statement_df.drop(0, level=1, axis=0, inplace=True) # Erase all ttm values as not necessary (trailing twelve months data not necessary)\n",
    "income_statement_df[\"Date\"] = pd.to_datetime(income_statement_df[\"Date\"]) # Updating column type to datetime\n",
    "\n",
    "# Clean column types\n",
    "cols=[i for i in income_statement_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "for col in cols:\n",
    "    income_statement_df[col] = income_statement_df[col].astype(str).str.replace(',','')\n",
    "    income_statement_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values but it works?\n",
    "    income_statement_df[col]= income_statement_df[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fefe8",
   "metadata": {},
   "source": [
    "### Market Stats Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "595fcefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_stats_df.rename(columns = {\n",
    "    \"Unnamed: 0\":\"Ticker\", \n",
    "    \"Breakdown\":\"Date\",\n",
    "    \"Market Cap (intraday)\":\"Market Cap Intraday\",\n",
    "    \"Trailing P/E\":\"Trailing PE\",\n",
    "    \"Forward P/E\":\"Forward PE\",\n",
    "    \"PEG Ratio (5 yr expected)\":\"PEG Ratio 5 Yr Expected\",\n",
    "    \"Price/Sales\":\"Price Over Sales\",\n",
    "    \"Price/Book\":\"Price Over Book\",\n",
    "    \"Enterprise Value/Revenue\":\"Enterprise Value Over Revenue\",\n",
    "    \"Enterprise Value/EBITDA\":\"Enterprise Value Over EBITDA\"\n",
    "    }, inplace = True)\n",
    "market_stats_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "market_stats_df.drop(0, level=1, axis=0, inplace=True) # Erase all \"as of date\" rows (1st row for every ticker - unnecessary data)\n",
    "market_stats_df[\"Date\"] = pd.to_datetime(market_stats_df[\"Date\"]) # Updating column type to datetime\n",
    "\n",
    "# Clean column types (all numerical columns except market cap are floats)\n",
    "cols=[i for i in market_stats_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "for col in cols:\n",
    "    market_stats_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values but it works?\n",
    "\n",
    "# replace \".\" with \"\" in only market cap and replace M with 4 zeros, replace B with 7 zeros\n",
    "market_stats_df[\"Market Cap Intraday\"] = market_stats_df[\"Market Cap Intraday\"].astype(str).str.replace(\"B\", \"0000000\")\n",
    "market_stats_df[\"Market Cap Intraday\"] = market_stats_df[\"Market Cap Intraday\"].astype(str).str.replace(\"M\", \"0000\")\n",
    "market_stats_df[\"Market Cap Intraday\"] = market_stats_df[\"Market Cap Intraday\"].astype(str).str.replace(\".\", \"\")\n",
    "market_stats_df[\"Market Cap Intraday\"] = market_stats_df[\"Market Cap Intraday\"].astype(str).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "dfd3aec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1l/mvv6j0wj6dq1cjsl5n7ybtxr0000gn/T/ipykernel_29279/3841816398.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  balance_sheet_df['Year'] = pd.to_datetime(balance_sheet_df['Date']).dt.year\n",
      "/var/folders/1l/mvv6j0wj6dq1cjsl5n7ybtxr0000gn/T/ipykernel_29279/3841816398.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  balance_sheet_df['Quarter'] = pd.to_datetime(balance_sheet_df['Date']).dt.quarter\n",
      "/var/folders/1l/mvv6j0wj6dq1cjsl5n7ybtxr0000gn/T/ipykernel_29279/3841816398.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  balance_sheet_df.at[index, 'Average Total Assets'] = average_TA\n"
     ]
    }
   ],
   "source": [
    "balance_sheet_df['Year'] = pd.to_datetime(balance_sheet_df['Date']).dt.year\n",
    "balance_sheet_df['Quarter'] = pd.to_datetime(balance_sheet_df['Date']).dt.quarter\n",
    "\n",
    "income_statement_df['Net Interest Income Past Yr'] = 0\n",
    "income_statement_df['Year'] = pd.to_datetime(income_statement_df['Date']).dt.year\n",
    "income_statement_df['Quarter'] = pd.to_datetime(income_statement_df['Date']).dt.quarter\n",
    "\n",
    "for index, row in balance_sheet_df.iterrows():\n",
    "# We need to get the previous year\n",
    "  curr_yr_ta = row['Total Assets']\n",
    "  ticker = row['Ticker']\n",
    "  prev_year = row['Year'] - 1\n",
    "\n",
    "  # We only care about yrs 2015 onwards\n",
    "  if prev_year <= 2013:\n",
    "    continue\n",
    "\n",
    "  current_quarter = row['Quarter']\n",
    "  filter_for_specific_row = balance_sheet_df[\n",
    "    (balance_sheet_df['Year'] == prev_year) & \n",
    "    (balance_sheet_df['Quarter'] == current_quarter) &\n",
    "    (balance_sheet_df['Ticker'] == ticker)].reset_index()\n",
    "  prev_year_TA = filter_for_specific_row['Total Assets'][0]\n",
    "  average_TA = (curr_yr_ta + prev_year_TA) / 2\n",
    "  balance_sheet_df.at[index, 'Average Total Assets'] = average_TA\n",
    "\n",
    "for index, row in income_statement_df.iterrows():\n",
    "  ticker = row['Ticker']\n",
    "  curr_yr = row['Year']\n",
    "  curr_qrtr = row['Quarter']\n",
    "  prev_yr = curr_yr - 1\n",
    "  \n",
    "  # We only care about yrs 2015 onwards\n",
    "  if prev_yr <= 2013:\n",
    "    continue\n",
    "\n",
    "  filtered_df_symbol = income_statement_df[\n",
    "    (income_statement_df['Ticker'] == ticker)\n",
    "    ].reset_index()\n",
    "  \n",
    "  filtered_df_year = filtered_df_symbol[\n",
    "    ((filtered_df_symbol['Year'] == curr_yr) & (filtered_df_symbol['Quarter'] <= curr_qrtr)) |\n",
    "    ((filtered_df_symbol['Year'] == prev_yr) & (filtered_df_symbol['Quarter'] > curr_qrtr))]\n",
    "  \n",
    "  NI = filtered_df_year['Net Interest Income'].sum()\n",
    "  income_statement_df.at[index, 'Net Interest Income Past Yr'] = NI\n",
    "\n",
    "\n",
    "# balance_sheet_df[\"NIM\"] = income_statement_df[\"Net Interest Income\"]/balance_sheet_df[\"Average Total Assets\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a3aa8",
   "metadata": {},
   "source": [
    "### Filter dates for all files to Jan 2017 - March 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "755d89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the updated DataFrames\n",
    "dataframes = {\n",
    "    'balance_sheet_df': balance_sheet_df,\n",
    "    'cashflow_statement_df': cashflow_statement_df,\n",
    "    'income_statement_df': income_statement_df,\n",
    "    'market_stats_df': market_stats_df\n",
    "}\n",
    "\n",
    "# Define the cutoff date\n",
    "cutoff_earliest_date = pd.to_datetime('2016-12-31')\n",
    "cutoff_latest_date = pd.to_datetime('2022-04-01')\n",
    "\n",
    "# Iterate over the dictionary items and filter the DataFrames\n",
    "for df_name, df in dataframes.items():\n",
    "    mask = (df['Date'] >= cutoff_earliest_date) & (df['Date'] <= cutoff_latest_date)\n",
    "    dataframes[df_name] = df[mask]\n",
    "\n",
    "# Access the updated DataFrames\n",
    "balance_sheet_df = dataframes['balance_sheet_df'].reset_index().drop(columns=[\"Index\", \"Ticker\", \"Year\", \"Quarter\"])\n",
    "cashflow_statement_df = dataframes['cashflow_statement_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n",
    "income_statement_df = dataframes['income_statement_df'].reset_index().drop(columns=[\"Index\", \"Ticker\", \"Year\", \"Quarter\"])\n",
    "market_stats_df = dataframes['market_stats_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9a4aaa",
   "metadata": {},
   "source": [
    "### Financial Ratio Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "66f9b36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Market Cap Intraday</th>\n",
       "      <th>ROE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>NIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>11240000000</td>\n",
       "      <td>4.166807</td>\n",
       "      <td>0.381823</td>\n",
       "      <td>0.026755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>11170000000</td>\n",
       "      <td>3.731161</td>\n",
       "      <td>0.357801</td>\n",
       "      <td>0.027101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>11000000000</td>\n",
       "      <td>3.962057</td>\n",
       "      <td>0.369836</td>\n",
       "      <td>0.026452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>10170000000</td>\n",
       "      <td>4.051195</td>\n",
       "      <td>0.375478</td>\n",
       "      <td>0.025642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EWBC</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>10470000000</td>\n",
       "      <td>3.878769</td>\n",
       "      <td>0.360434</td>\n",
       "      <td>0.026612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>12330000000</td>\n",
       "      <td>2.804205</td>\n",
       "      <td>0.228861</td>\n",
       "      <td>0.029622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>9860000000</td>\n",
       "      <td>3.660760</td>\n",
       "      <td>0.292823</td>\n",
       "      <td>0.028146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>9260000000</td>\n",
       "      <td>3.159253</td>\n",
       "      <td>0.254529</td>\n",
       "      <td>0.027060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>9760000000</td>\n",
       "      <td>2.695911</td>\n",
       "      <td>0.218651</td>\n",
       "      <td>0.026206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>8940000000</td>\n",
       "      <td>2.730666</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.025747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>659 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker Symbol       Date  Market Cap Intraday       ROE       ROA   \n",
       "0            EWBC 2022-03-31          11240000000  4.166807  0.381823  \\\n",
       "1            EWBC 2021-12-31          11170000000  3.731161  0.357801   \n",
       "2            EWBC 2021-09-30          11000000000  3.962057  0.369836   \n",
       "3            EWBC 2021-06-30          10170000000  4.051195  0.375478   \n",
       "4            EWBC 2021-03-31          10470000000  3.878769  0.360434   \n",
       "..            ...        ...                  ...       ...       ...   \n",
       "654         SIVBQ 2017-12-31          12330000000  2.804205  0.228861   \n",
       "655         SIVBQ 2017-09-30           9860000000  3.660760  0.292823   \n",
       "656         SIVBQ 2017-06-30           9260000000  3.159253  0.254529   \n",
       "657         SIVBQ 2017-03-31           9760000000  2.695911  0.218651   \n",
       "658         SIVBQ 2016-12-31           8940000000  2.730666  0.222600   \n",
       "\n",
       "          NIM  \n",
       "0    0.026755  \n",
       "1    0.027101  \n",
       "2    0.026452  \n",
       "3    0.025642  \n",
       "4    0.026612  \n",
       "..        ...  \n",
       "654  0.029622  \n",
       "655  0.028146  \n",
       "656  0.027060  \n",
       "657  0.026206  \n",
       "658  0.025747  \n",
       "\n",
       "[659 rows x 6 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "\n",
    "financial_ratios = market_stats_df.drop(columns = [\n",
    "    'Enterprise Value','Trailing PE', 'Forward PE', 'PEG Ratio 5 Yr Expected','Price Over Sales', \n",
    "    'Price Over Book', 'Enterprise Value Over Revenue', 'Enterprise Value Over EBITDA'])\n",
    "\n",
    "financial_ratios[\"ROE\"] = (income_statement_df[\"Net Income Common Stockholders\"] / balance_sheet_df[\"Common Stock Equity\"]) * 100\n",
    "financial_ratios[\"ROA\"] = (income_statement_df[\"Net Income Common Stockholders\"] / balance_sheet_df[\"Total Assets\"]) * 100\n",
    "financial_ratios[\"NIM\"] = income_statement_df[\"Net Interest Income Past Yr\"]/balance_sheet_df[\"Average Total Assets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce85433d",
   "metadata": {},
   "source": [
    "### df to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2b39ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves compiled dataframes as csv files under compiled_CSV\n",
    "os.makedirs('compiled_CSV', exist_ok=True)  \n",
    "balance_sheet_df.to_csv('compiled_CSV/balance_sheet.csv') \n",
    "cashflow_statement_df.to_csv('compiled_CSV/cashflow_statement.csv') \n",
    "income_statement_df.to_csv('compiled_CSV/income_statement.csv') \n",
    "market_stats_df.to_csv('compiled_CSV/market_stats.csv') \n",
    "financial_ratios.to_csv('compiled_CSV/financial_ratios.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a2761",
   "metadata": {},
   "source": [
    "### Loading objects/csv files to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ee6ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded balance_sheet.csv to ds4a-c1-team22\n",
      "Uploaded market_stats.csv to ds4a-c1-team22\n",
      "Uploaded company_info.csv to ds4a-c1-team22\n",
      "Uploaded income_statement.csv to ds4a-c1-team22\n",
      "Uploaded financial_ratios_df.csv to ds4a-c1-team22\n",
      "Uploaded cashflow_statement.csv to ds4a-c1-team22\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "access_key = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "secret_key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "def get_file_paths(folder_path):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):  # Filter CSV files\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "def upload_files_to_s3(file_paths, bucket_name):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
    "    for file_path in file_paths:\n",
    "        file_name = file_path.split('/')[-1]  # Extract the file name from the path\n",
    "        s3.upload_file(file_path, bucket_name, file_name)\n",
    "        print(f\"Uploaded {file_name} to {bucket_name}\")\n",
    "\n",
    "# Folder path containing the CSV files\n",
    "folder_path = os.getcwd() + \"/compiled_CSV\"\n",
    "\n",
    "# Call the function to get file paths\n",
    "file_paths = get_file_paths(folder_path)\n",
    "\n",
    "# Name of the S3 bucket\n",
    "bucket_name = 'ds4a-c1-team22'\n",
    "\n",
    "# Call the function to upload files\n",
    "upload_files_to_s3(file_paths, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf8120",
   "metadata": {},
   "source": [
    "### Company Info CSV cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_stats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276230a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d427398",
   "metadata": {},
   "source": [
    "### Apache Airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c2afbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DAG: etl_taskflow_api>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "import pendulum\n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "@dag(\n",
    "    schedule=None,\n",
    "    start_date=pendulum.datetime(2023, 9, 30, tz=\"UTC\"),\n",
    "    catchup=False,\n",
    "    tags=[\"example\"],\n",
    ")\n",
    "def etl_taskflow_api():\n",
    "    \"\"\"\n",
    "    ### TaskFlow API Tutorial Documentation\n",
    "    This is a simple data pipeline example which demonstrates the use of\n",
    "    the TaskFlow API using three simple tasks for Extract, Transform, and Load.\n",
    "    Documentation that goes along with the Airflow TaskFlow API tutorial is\n",
    "    located\n",
    "    [here](https://airflow.apache.org/docs/apache-airflow/stable/tutorial_taskflow_api.html)\n",
    "    \"\"\"\n",
    "    @task()\n",
    "    def extract():\n",
    "        \"\"\"\n",
    "        #### Extract task\n",
    "        \"\"\"\n",
    "        # TODO: Remove this return\n",
    "        return True\n",
    "        stock_tickers_arr = [\n",
    "        # Add Stock Symbols here\n",
    "        ]\n",
    "\n",
    "        # Install and set ChromeDriver\n",
    "        driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "        # Login here\n",
    "        login(\"kevinator112233@yahoo.com\", \"\")\n",
    "\n",
    "        for stock_ticker in stock_tickers_arr:\n",
    "            save_all_financial_statements(stock_ticker)\n",
    "            save_market_cap(stock_ticker)\n",
    "\n",
    "        driver.quit()\n",
    "    @task(multiple_outputs=True)\n",
    "    def compile():\n",
    "        \"\"\"\n",
    "        #### Compile task\n",
    "        A simple Transform task which takes in the collection of order data and\n",
    "        computes the total order value.\n",
    "        \"\"\"\n",
    "\n",
    "        #compilation of all appropriate csv files\n",
    "        main_path = os.getcwd() + \"/CSV\"\n",
    "\n",
    "        # Initializing dicts\n",
    "        balance_sheet_df_collection = {}\n",
    "        cashflow_statement_df_collection = {}\n",
    "        income_statement_df_collection = {}\n",
    "        market_stats_df_collection = {}\n",
    "\n",
    "        collections = {\n",
    "            \"balance_sheet_quarterly.csv\": balance_sheet_df_collection,\n",
    "            \"cashflow_statement_quarterly.csv\": cashflow_statement_df_collection,\n",
    "            \"income_statement_quarterly.csv\": income_statement_df_collection,\n",
    "            \"market_stats.csv\": market_stats_df_collection\n",
    "        }\n",
    "\n",
    "        def process_csv_file(current_path, folder):\n",
    "            copy_df = pd.read_csv(current_path)\n",
    "            copy_df[\"Unnamed: 0\"] = (copy_df[\"Unnamed: 0\"] >= 0).astype(int).replace(1, folder)\n",
    "            column_names = copy_df.columns\n",
    "            return pd.DataFrame(copy_df, columns=column_names)\n",
    "\n",
    "        for folder in os.listdir(main_path):\n",
    "            for csv_file in os.listdir(os.path.join(main_path, folder)):\n",
    "                current_path = os.path.join(main_path, folder, csv_file)\n",
    "                if csv_file in collections:\n",
    "                    collections[csv_file][folder] = process_csv_file(current_path, folder)\n",
    "\n",
    "        balance_sheet_df = pd.concat(balance_sheet_df_collection)\n",
    "        cashflow_statement_df = pd.concat(cashflow_statement_df_collection)\n",
    "        income_statement_df = pd.concat(income_statement_df_collection)\n",
    "        market_stats_df = pd.concat(market_stats_df_collection)\n",
    "        return {\n",
    "            balance_sheet_df:balance_sheet_df,\n",
    "            cashflow_statement_df:cashflow_statement_df,\n",
    "            income_statement_df:income_statement_df,\n",
    "            market_stats_df:market_stats_df\n",
    "        }\n",
    "    @task()\n",
    "    def transform(dataframes:object):\n",
    "\n",
    "        # BALANCE SHEET\n",
    "\n",
    "        balance_sheet_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "        balance_sheet_df[\"Date\"] = pd.to_datetime(balance_sheet_df[\"Date\"])\n",
    "        balance_sheet_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "\n",
    "        # Clean column types\n",
    "        cols=[i for i in balance_sheet_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "        for col in cols:\n",
    "            balance_sheet_df[col] = balance_sheet_df[col].astype(str).str.replace(',','')\n",
    "            balance_sheet_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values\n",
    "            balance_sheet_df[col]= balance_sheet_df[col].astype(float)\n",
    "\n",
    "        # CASH FLOWS\n",
    "        cashflow_statement_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "        cashflow_statement_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "        cashflow_statement_df.drop(0, level=1, axis=0, inplace=True) # Erase all ttm values as not necessary (trailing twelve months data not necessary)\n",
    "        cashflow_statement_df[\"Date\"] = pd.to_datetime(cashflow_statement_df[\"Date\"]) # Updating column type to datetime\n",
    "        \n",
    "        # Clean column types\n",
    "        cols=[i for i in cashflow_statement_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "        for col in cols:\n",
    "            cashflow_statement_df[col] = cashflow_statement_df[col].astype(str).str.replace(',','')\n",
    "            cashflow_statement_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values but it works?\n",
    "            cashflow_statement_df[col]= cashflow_statement_df[col].astype(float)\n",
    "\n",
    "        # INCOME STATEMENT\n",
    "        income_statement_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "        income_statement_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "        income_statement_df.drop(0, level=1, axis=0, inplace=True) # Erase all ttm values as not necessary (trailing twelve months data not necessary)\n",
    "        income_statement_df[\"Date\"] = pd.to_datetime(income_statement_df[\"Date\"]) # Updating column type to datetime\n",
    "\n",
    "        # Clean column types\n",
    "        cols=[i for i in income_statement_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "        for col in cols:\n",
    "            income_statement_df[col] = income_statement_df[col].astype(str).str.replace(',','')\n",
    "            income_statement_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values but it works?\n",
    "            income_statement_df[col]= income_statement_df[col].astype(float)\n",
    "\n",
    "        # MARKET STATS\n",
    "        market_stats_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "        market_stats_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "        market_stats_df.drop(0, level=1, axis=0, inplace=True) # Erase all \"as of date\" rows (1st row for every ticker - unnecessary data)\n",
    "        market_stats_df[\"Date\"] = pd.to_datetime(market_stats_df[\"Date\"]) # Updating column type to datetime\n",
    "        \n",
    "        # Clean column types (all numerical columns except market cap are floats)\n",
    "        cols=[i for i in market_stats_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "        for col in cols:\n",
    "            market_stats_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values but it works?\n",
    "        \n",
    "        # replace \".\" with \"\" in only market cap and replace M with 4 zeros, replace B with 7 zeros\n",
    "        market_stats_df[\"Market Cap (intraday)\"] = market_stats_df[\"Market Cap (intraday)\"].astype(str).str.replace(\"B\", \"0000000\")\n",
    "        market_stats_df[\"Market Cap (intraday)\"] = market_stats_df[\"Market Cap (intraday)\"].astype(str).str.replace(\"M\", \"0000\")\n",
    "        market_stats_df[\"Market Cap (intraday)\"] = market_stats_df[\"Market Cap (intraday)\"].astype(str).str.replace(\".\", \"\")\n",
    "        market_stats_df[\"Market Cap (intraday)\"] = market_stats_df[\"Market Cap (intraday)\"].astype(str).astype(int)\n",
    "\n",
    "        dataframes = {\n",
    "            'balance_sheet_df': balance_sheet_df,\n",
    "            'cashflow_statement_df': cashflow_statement_df,\n",
    "            'income_statement_df': income_statement_df,\n",
    "            'market_stats_df': market_stats_df\n",
    "        }\n",
    "        \n",
    "        # Define the cutoff date\n",
    "        cutoff_earliest_date = pd.to_datetime('2016-12-31')\n",
    "        cutoff_latest_date = pd.to_datetime('2022-04-01')\n",
    "        \n",
    "        # Iterate over the dictionary items and filter the DataFrames\n",
    "        for df_name, df in dataframes.items():\n",
    "            mask = (df['Date'] >= cutoff_earliest_date) & (df['Date'] <= cutoff_latest_date)\n",
    "            dataframes[df_name] = df[mask]\n",
    "        \n",
    "        # Access the updated DataFrames\n",
    "        balance_sheet_df = dataframes['balance_sheet_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n",
    "        cashflow_statement_df = dataframes['cashflow_statement_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n",
    "        income_statement_df = dataframes['income_statement_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n",
    "        market_stats_df = dataframes['market_stats_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n",
    "        \n",
    "        # Saves compiled dataframes as csv files under compiled_CSV\n",
    "        os.makedirs('compiled_CSV', exist_ok=True)  \n",
    "        balance_sheet_df.to_csv('compiled_CSV/balance_sheet.csv') \n",
    "        cashflow_statement_df.to_csv('compiled_CSV/cashflow_statement.csv') \n",
    "        income_statement_df.to_csv('compiled_CSV/income_statement.csv') \n",
    "        market_stats_df.to_csv('compiled_CSV/market_stats.csv') \n",
    "    @task()\n",
    "    def load(dataframes: object):\n",
    "        \"\"\"\n",
    "        #### Load task\n",
    "        \"\"\"\n",
    "        access_key = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "        secret_key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "        # TODO: Remove this return\n",
    "        return True\n",
    "        def get_file_paths(folder_path):\n",
    "            file_paths = []\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('.csv'):  # Filter CSV files\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        file_paths.append(file_path)\n",
    "            return file_paths\n",
    "\n",
    "        def upload_files_to_s3(file_paths, bucket_name):\n",
    "            s3 = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
    "            for file_path in file_paths:\n",
    "                file_name = file_path.split('/')[-1]  # Extract the file name from the path\n",
    "                s3.upload_file(file_path, bucket_name, file_name)\n",
    "                print(f\"Uploaded {file_name} to {bucket_name}\")\n",
    "\n",
    "        # Folder path containing the CSV files\n",
    "        folder_path = os.getcwd() + \"/compiled_CSV\"\n",
    "\n",
    "        # Call the function to get file paths\n",
    "        file_paths = get_file_paths(folder_path)\n",
    "\n",
    "        # Name of the S3 bucket\n",
    "        bucket_name = 'ds4a-c1-team22'\n",
    "\n",
    "        # Call the function to upload files\n",
    "        upload_files_to_s3(file_paths, bucket_name)\n",
    "    \n",
    "    extract()\n",
    "    dataframes = compile()\n",
    "    transform(dataframes)\n",
    "    load(dataframes)\n",
    "etl_taskflow_api()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
