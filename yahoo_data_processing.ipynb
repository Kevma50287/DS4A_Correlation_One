{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation of all appropriate CSV files\n",
    "\n",
    "**More info to be added soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilation of all appropriate csv files\n",
    "main_path = os.getcwd() + \"/CSV\"\n",
    "\n",
    "# Initializing dicts\n",
    "balance_sheet_df_collection = {}\n",
    "cashflow_statement_df_collection = {}\n",
    "income_statement_df_collection = {}\n",
    "market_stats_df_collection = {}\n",
    "\n",
    "collections = {\n",
    "    \"balance_sheet_quarterly.csv\": balance_sheet_df_collection,\n",
    "    \"cashflow_statement_quarterly.csv\": cashflow_statement_df_collection,\n",
    "    \"income_statement_quarterly.csv\": income_statement_df_collection,\n",
    "    \"market_stats.csv\": market_stats_df_collection\n",
    "}\n",
    "\n",
    "def process_csv_file(current_path, folder):\n",
    "    copy_df = pd.read_csv(current_path)\n",
    "    copy_df[\"Unnamed: 0\"] = (copy_df[\"Unnamed: 0\"] >= 0).astype(int).replace(1, folder)\n",
    "    column_names = copy_df.columns\n",
    "    return pd.DataFrame(copy_df, columns=column_names)\n",
    "\n",
    "for folder in os.listdir(main_path):\n",
    "    for csv_file in os.listdir(os.path.join(main_path, folder)):\n",
    "        current_path = os.path.join(main_path, folder, csv_file)\n",
    "        \n",
    "        if csv_file in collections:\n",
    "            collections[csv_file][folder] = process_csv_file(current_path, folder)\n",
    "\n",
    "\n",
    "balance_sheet_df = pd.concat(balance_sheet_df_collection)\n",
    "cashflow_statement_df = pd.concat(cashflow_statement_df_collection)\n",
    "income_statement_df = pd.concat(income_statement_df_collection)\n",
    "market_stats_df = pd.concat(market_stats_df_collection)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up of compiled dataframes\n",
    "\n",
    " - balance_sheet_df\n",
    " - cashflow_statement_df\n",
    " - income_statement_df\n",
    " - market_stats_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Sheet Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "balance_sheet_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "balance_sheet_df[\"Date\"] = pd.to_datetime(balance_sheet_df[\"Date\"])\n",
    "balance_sheet_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "# Clean column types\n",
    "cols=[i for i in balance_sheet_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "for col in cols:\n",
    "    balance_sheet_df[col] = balance_sheet_df[col].astype(str).str.replace(',','')\n",
    "    balance_sheet_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values\n",
    "    balance_sheet_df[col]= balance_sheet_df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "balance_sheet_df[\"Total Assets\"].dtypes\n",
    "\n",
    "# Alternatively, you can use isinstance()\n",
    "is_float = all(isinstance(value, float) for value in balance_sheet_df['Total Assets'])\n",
    "print(is_float)  # Output: True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cashflow Statement Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashflow_statement_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "cashflow_statement_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "cashflow_statement_df.drop(0, level=1, axis=0, inplace=True) # Erase all ttm values as not necessary (trailing twelve months data not necessary)\n",
    "cashflow_statement_df[\"Date\"] = pd.to_datetime(cashflow_statement_df[\"Date\"]) # Updating column type to datetime\n",
    "\n",
    "# Clean column types\n",
    "cols=[i for i in cashflow_statement_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "for col in cols:\n",
    "    cashflow_statement_df[col] = cashflow_statement_df[col].astype(str).str.replace(',','')\n",
    "    cashflow_statement_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values but it works?\n",
    "    cashflow_statement_df[col]= cashflow_statement_df[col].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income Statement Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_statement_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "income_statement_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "income_statement_df.drop(0, level=1, axis=0, inplace=True) # Erase all ttm values as not necessary (trailing twelve months data not necessary)\n",
    "income_statement_df[\"Date\"] = pd.to_datetime(income_statement_df[\"Date\"]) # Updating column type to datetime\n",
    "\n",
    "# Clean column types\n",
    "cols=[i for i in income_statement_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "for col in cols:\n",
    "    income_statement_df[col] = income_statement_df[col].astype(str).str.replace(',','')\n",
    "    income_statement_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values but it works?\n",
    "    income_statement_df[col]= income_statement_df[col].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Stats Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_stats_df.rename(columns = {\"Unnamed: 0\":\"Ticker\", \"Breakdown\":\"Date\"}, inplace = True)\n",
    "market_stats_df.index.set_names(['Ticker Symbol', 'Index'], inplace = True) # Set index names \n",
    "market_stats_df.drop(0, level=1, axis=0, inplace=True) # Erase all \"as of date\" rows (1st row for every ticker - unnecessary data)\n",
    "market_stats_df[\"Date\"] = pd.to_datetime(market_stats_df[\"Date\"]) # Updating column type to datetime\n",
    "\n",
    "# Clean column types (all numerical columns except market cap are floats)\n",
    "cols=[i for i in market_stats_df.columns if i not in [\"Ticker\",\"Date\"]]\n",
    "for col in cols:\n",
    "    market_stats_df[col].replace('-', np.nan, inplace = True) #double check no negative values, find way to replace \"-\" for null values NaN without replacing negative values but it works?\n",
    "\n",
    "# replace \".\" with \"\" in only market cap and replace M with 4 zeros, replace B with 7 zeros\n",
    "market_stats_df[\"Market Cap (intraday)\"] = market_stats_df[\"Market Cap (intraday)\"].astype(str).str.replace(\"B\", \"0000000\")\n",
    "market_stats_df[\"Market Cap (intraday)\"] = market_stats_df[\"Market Cap (intraday)\"].astype(str).str.replace(\"M\", \"0000\")\n",
    "market_stats_df[\"Market Cap (intraday)\"] = market_stats_df[\"Market Cap (intraday)\"].astype(str).str.replace(\".\", \"\")\n",
    "market_stats_df[\"Market Cap (intraday)\"] = market_stats_df[\"Market Cap (intraday)\"].astype(str).astype(int)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dates for all files to Jan 2017 - March 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the DataFrames\n",
    "dataframes = {\n",
    "    'balance_sheet_df': balance_sheet_df,\n",
    "    'cashflow_statement_df': cashflow_statement_df,\n",
    "    'income_statement_df': income_statement_df,\n",
    "    'market_stats_df': market_stats_df\n",
    "}\n",
    "\n",
    "# Define the cutoff date\n",
    "cutoff_earliest_date = pd.to_datetime('2016-12-31')\n",
    "cutoff_latest_date = pd.to_datetime('2022-04-01')\n",
    "\n",
    "# Iterate over the dictionary items and filter the DataFrames\n",
    "for df_name, df in dataframes.items():\n",
    "    mask = (df['Date'] >= cutoff_earliest_date) & (df['Date'] <= cutoff_latest_date)\n",
    "    dataframes[df_name] = df[mask]\n",
    "\n",
    "# Access the updated DataFrames\n",
    "balance_sheet_df = dataframes['balance_sheet_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n",
    "cashflow_statement_df = dataframes['cashflow_statement_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n",
    "income_statement_df = dataframes['income_statement_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n",
    "market_stats_df = dataframes['market_stats_df'].reset_index().drop(columns=[\"Index\", \"Ticker\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves compiled dataframes as csv files under compiled_CSV\n",
    "os.makedirs('compiled_CSV', exist_ok=True)  \n",
    "balance_sheet_df.to_csv('compiled_CSV/balance_sheet.csv') \n",
    "cashflow_statement_df.to_csv('compiled_CSV/cashflow_statement.csv') \n",
    "income_statement_df.to_csv('compiled_CSV/income_statement.csv') \n",
    "market_stats_df.to_csv('compiled_CSV/market_stats.csv') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading objects/csv files to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded balance_sheet.csv to ds4a-c1-team22\n",
      "Uploaded market_stats.csv to ds4a-c1-team22\n",
      "Uploaded company_info.csv to ds4a-c1-team22\n",
      "Uploaded income_statement.csv to ds4a-c1-team22\n",
      "Uploaded financial_ratios_df.csv to ds4a-c1-team22\n",
      "Uploaded cashflow_statement.csv to ds4a-c1-team22\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "access_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "def get_file_paths(folder_path):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):  # Filter CSV files\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "def upload_files_to_s3(file_paths, bucket_name):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
    "    for file_path in file_paths:\n",
    "        file_name = file_path.split('/')[-1]  # Extract the file name from the path\n",
    "        s3.upload_file(file_path, bucket_name, file_name)\n",
    "        print(f\"Uploaded {file_name} to {bucket_name}\")\n",
    "\n",
    "# Folder path containing the CSV files\n",
    "folder_path = os.getcwd() + \"/compiled_CSV\"\n",
    "\n",
    "# Call the function to get file paths\n",
    "file_paths = get_file_paths(folder_path)\n",
    "\n",
    "# Name of the S3 bucket\n",
    "bucket_name = 'ds4a-c1-team22'\n",
    "\n",
    "# Call the function to upload files\n",
    "upload_files_to_s3(file_paths, bucket_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company Info CSV cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticker Symbol', 'Date', 'Market Cap (intraday)', 'Enterprise Value',\n",
       "       'Trailing P/E', 'Forward P/E', 'PEG Ratio (5 yr expected)',\n",
       "       'Price/Sales', 'Price/Book', 'Enterprise Value/Revenue',\n",
       "       'Enterprise Value/EBITDA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_stats_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Ratio Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticker Symbol', 'Date', 'Total Assets',\n",
       "       'Cash, Cash Equivalents & Federal Funds Sold',\n",
       "       'Cash And Cash Equivalents', 'Cash', 'Cash Equivalents',\n",
       "       'Cash And Due from Banks', 'Interest Bearing Deposits Assets',\n",
       "       'Restricted Cash And Investments',\n",
       "       ...\n",
       "       'Properties', 'Line of Credit', 'Unrealized Gain Loss',\n",
       "       'Non Current Deferred Taxes Liabilities', 'Defined Pension Benefit',\n",
       "       'Due to Related Parties', 'Current Deferred Liabilities',\n",
       "       'Current Deferred Taxes Liabilities', 'Minimum Pension Liabilities',\n",
       "       'Other Capital Stock'],\n",
       "      dtype='object', length=133)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_sheet_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Net Interest Income</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Average Total Assets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>EWBC</td>\n",
       "      <td>415613.0</td>\n",
       "      <td>62241456.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>EWBC</td>\n",
       "      <td>405697.0</td>\n",
       "      <td>60870701.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>EWBC</td>\n",
       "      <td>395706.0</td>\n",
       "      <td>60959110.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>EWBC</td>\n",
       "      <td>376473.0</td>\n",
       "      <td>59854876.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>EWBC</td>\n",
       "      <td>353695.0</td>\n",
       "      <td>56874146.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>393706.0</td>\n",
       "      <td>51214467.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>373974.0</td>\n",
       "      <td>50754287.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>342696.0</td>\n",
       "      <td>48400379.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>309993.0</td>\n",
       "      <td>46413339.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>SIVBQ</td>\n",
       "      <td>296605.0</td>\n",
       "      <td>44683660.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>659 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date Ticker  Net Interest Income  Total Assets  Average Total Assets\n",
       "0   2022-03-31   EWBC             415613.0    62241456.0                   NaN\n",
       "1   2021-12-31   EWBC             405697.0    60870701.0                   0.0\n",
       "2   2021-09-30   EWBC             395706.0    60959110.0                   0.0\n",
       "3   2021-06-30   EWBC             376473.0    59854876.0                   NaN\n",
       "4   2021-03-31   EWBC             353695.0    56874146.0                   0.0\n",
       "..         ...    ...                  ...           ...                   ...\n",
       "654 2017-12-31  SIVBQ             393706.0    51214467.0                   0.0\n",
       "655 2017-09-30  SIVBQ             373974.0    50754287.0                   0.0\n",
       "656 2017-06-30  SIVBQ             342696.0    48400379.0                   0.0\n",
       "657 2017-03-31  SIVBQ             309993.0    46413339.0                   0.0\n",
       "658 2016-12-31  SIVBQ             296605.0    44683660.0                   0.0\n",
       "\n",
       "[659 rows x 5 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "\n",
    "financial_ratios = market_stats_df.drop(\n",
    "  columns = [\n",
    "    'Enterprise Value','Trailing P/E', 'Forward P/E', \n",
    "    'PEG Ratio (5 yr expected)','Price/Sales', \n",
    "    'Price/Book', 'Enterprise Value/Revenue', 'Enterprise Value/EBITDA'\n",
    "    ]\n",
    "  )\n",
    "\n",
    "financial_ratios[\"ROE\"] = (income_statement_df[\"Net Income Common Stockholders\"] / balance_sheet_df[\"Common Stock Equity\"]) * 100\n",
    "financial_ratios[\"ROA\"] = (income_statement_df[\"Net Income Common Stockholders\"] / balance_sheet_df[\"Total Assets\"]) * 100\n",
    "#financial_ratios[\"CAR\"] =\n",
    "\n",
    "d1 = income_statement_df[[\"Date\", \"Ticker\",\"Net Interest Income\"]]\n",
    "d2 = balance_sheet_df[[\"Date\", \"Ticker\",\"Total Assets\"]]\n",
    "\n",
    "\n",
    "merge_NI_and_TA = pd.merge(d1, d2, on=['Date', 'Ticker'])\n",
    "merge_NI_and_TA[merge_NI_and_TA[\"Date\"] == merge_NI_and_TA[\"Date\"] + pd.DateOffset(years=-1)]\n",
    "\n",
    "# for index, row in merge_NI_and_TA.iterrows():\n",
    "#     curr_year_total_assets = row[\"Total Assets\"]\n",
    "#     prior_year = pd.Timestamp(row[\"Date\"].date() - relativedelta(years=1))\n",
    "#     prior_year_total_assets = merge_NI_and_TA[merge_NI_and_TA[\"Date\"] == prior_year][\"Total Assets\"]\n",
    "#     # print(row[\"Net Interest Income\"], curr_year_total_assets, prior_year_total_assets)\n",
    "#     NI = row[\"Net Interest Income\"]\n",
    "#     val = NI / ((curr_year_total_assets + prior_year_total_assets) / 2)\n",
    "#     print(merge_NI_and_TA.loc(merge_NI_and_TA[\"Average Total Assets\"]))\n",
    "#     print(merge_NI_and_TA.loc[ (merge_NI_and_TA[\"Date\"] == row[\"Date\"]) & (merge_NI_and_TA[\"Ticker\"] == row[\"Ticker\"]) ][\"Average Total Assets\"])\n",
    "\n",
    "\n",
    "# financial_ratios[\"NIM\"] = (income_statement_df[\"Net Interest Income\"] / ((balance_sheet_df)/ 2)#missing average invested assets\n",
    "\n",
    "#financial_ratios[\"NPL\"] =\n",
    "\n",
    "# financial_ratios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2 (v3.11.2:878ead1ac1, Feb  7 2023, 10:02:41) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
